{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d361ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include necessary imports\n",
    "import os\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c67e7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "folder_path = 'RAVDESS/'\n",
    "# save all the audio files from all the actors\n",
    "for dirname in os.listdir(folder_path):\n",
    "    if dirname != \".DS_Store\":\n",
    "        for filename in os.listdir(folder_path + dirname):\n",
    "            # add both audio waveform and emotion label\n",
    "            if (filename.endswith(\".wav\")):\n",
    "                emotion = filename[7:8]\n",
    "                # include every emotion except calm since its not included in TESS\n",
    "                audio_path = folder_path + dirname + \"/\" + filename\n",
    "                # convert audio to tensor before appending\n",
    "                data, sample_rate = sf.read(audio_path)\n",
    "                audio_tensor = torch.tensor(data)\n",
    "                label = int(emotion) - 1\n",
    "                audio_data.append((audio_tensor, torch.tensor([label])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc8da5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our first model (NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9e5e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75011af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetune (hyperparameters, move around test data (refer to notes), etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a19fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with new data + evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc27f4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make any other changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc96a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sheet music + audio (musicAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad609d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new models if time permits (follow steps 3 - 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5a3b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095d0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Front end ** if time permits\n",
    "# - Interactive sheet music\n",
    "# - musescore front end??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9df8f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclude project"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
